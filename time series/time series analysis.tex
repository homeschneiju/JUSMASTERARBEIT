\documentclass[12pt,titlepage]{article}
\usepackage{natbib}
\usepackage{textcomp}
\begin{document}
Time series forecasting with (S)AR(I)MA models is a well-established concept that has been studied thoroughly for many decades and provides good forecasting accuracy \citep{Arlt.2017, Khandelwal.2015}.It has found application in many domains such as economy (MEHR QUELLEN), 

The assumption ARIMA models are based on is that the values of a target variable are generated by a linear combination of past values of the same variable and white noise \citep{Khandelwal.2015}, thus making it a stochastic process, "i.e. an ordered sequence of random variables" \citep{Andreoni.2006}, with data entries at equally distant intervals \citep{Hunt.2003}.\\
Further, mathematical assumptions are stationarity and homoscedasticity.\\
(Weak) Stationarity is fulfilled when mean and covariance are independent oft time \textit{t}, and the relationship between two values at time points \textit{t} and \textit{t + i} is the same as the relationship between two values at time points \textit{s} and \textit{s + i}, i.e. independent of the exact position in the time series, but provided the distance between any two values is the same \citep{Vogel.2015}.\\


Autoregressive (AR) processes are processes where a value of a variable at \textit{t} depends on weighted previous values of the variable itself plus a white noise term $\epsilon \sim  WN(0, \sigma_{\epsilon}^2)$. An \textit{AR(p)} process of order \textit{p} has the form:
\begin{equation}
y_{t} = \phi_{1} y_{t-1} + \phi_{2} y_{t-2} + ... + \phi_{p} y_{t-p} +\epsilon_{t}
\end{equation}

Moving Average (MA) processes of order \textit{q} are denoted like this:
\begin{equation}
Y_{t} = \mu + \epsilon_{t} - \phi_{1}\epsilon_{t-1} - \phi_{2}\epsilon_{t-2} - ... - +\phi_{q}\epsilon_{t-q}
\end{equation}
, i.e. the value of a target value at \textit{t} depends on a white noise and previous white noise weighted by $\phi$. Note that \mu may be 0 and MA-processes are stationary.

ERKLÃ„RE trend differencing, transformation, seasonality

However, the process underlying time series data may change over time - it is subject to uncertainty \citep{Adhikari.2015}. A time series model may be biased or overfitted as well as its parameters misspecified. \\

\subsection{AR(I)MA models}

As the name suggests, AR(I)MA(p,d,q) - auto-regressive integrated moving average - models model time series data with an AR and an MA component, and trend in data through differencing (which is the "I-part"). \\
The parameters \textit{p}, \textit{d}, and \textit{q} respectively denote the order of the AR component, the degree of differencing and the MA component \citep{Zhao.07022018}.
If there is also a seasonal component - thus a SARIMA model is to be fitted - there are additional parameters P, D, Q referring to the seasonal orders (or degrees) of AR, differencing and MA.


The parameters p,q,P and Q may be identified using an Information Criterion suchs as BIC or AIC. (FORMEL falls nicht schon geschehen oder Referenz auf Formel)
In order to appropriately model time series data, \citep{Box.1976} proposed a method to identify suitable parameters - AR, MA and differencing - of an ARIMA model. It consists of the following four steps: \\
1. Visual identification of model parameter through ACF for MA- and PACF for AR-parameters.



\bibliographystyle{apalike}
\bibliography{timeseries}
\end{document}